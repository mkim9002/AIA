from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import to_categorical
import pandas as pd
import numpy as np

text = '나는 진짜 매우 매우 맛있는 밥을 엄청 마구 마구 마구 먹었다.'

token = Tokenizer()
token.fit_on_texts([text])

print(token.word_index)  #{'마구': 1, '매우': 2, '나는': 3, '진짜': 4, '맛있는': 5, '밥을': 6, '엄청': 7, '먹었다': 8}
print(token.word_counts)  #OrderedDict([('나는', 1), ('진짜', 1), ('매우', 2), ('맛있는', 1), ('밥을', 1), ('엄청', 1), ('마구', 3), ('먹었다', 1)])

# convert text to sequence of integers
x = token.texts_to_sequences([text])[0]
print(x)  # [3, 4, 2, 2, 5, 6, 7, 1, 1, 1, 8]

# convert integers to text
word_index = token.word_index
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
text = ' '.join([reverse_word_index.get(i, '?') for i in x])
print(text)  # '나는 진짜 매우 매우 맛있는 밥을 엄청 마구 마구 마구 먹었다'

# one-hot encode
x_one_hot = []
for i in x:
    x_one_hot.append(to_categorical(i, num_classes=len(word_index)+1))
x = np.array(x_one_hot)
print(x)
print(x.shape)  #(11, 9)

# convert to pandas dataframe
x_df = pd.DataFrame(x)

# use get_dummies on each column separately
x_one_hot = []
for i in range(x.shape[1]):
    col = x_df[i]
    one_hot = pd.get_dummies(col)
    x_one_hot.append(one_hot.values)

# concatenate one-hot encoded columns
x = np.concatenate(x_one_hot, axis=1)
print(x)
print(x.shape)